{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchinfo import summary\n",
    "\n",
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *\n",
    "\n",
    "import CsvFix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_person = 1 # 0 = kikuzo, 1 = amaya, 2 = rinto\n",
    "subject_num = 9\n",
    "test_ratio = 0.2\n",
    "\n",
    "seq_len = 128\n",
    "input_size = 6\n",
    "train_size = 350\n",
    "test_size = 20\n",
    "\n",
    "# test_minisize = 50\n",
    "output_size = 2\n",
    "hidden_size_1 = 50\n",
    "hidden_size_2 = 70\n",
    "epoch_num = 200\n",
    "batch = 16\n",
    "learning_rate = 0.01\n",
    "path = \"./Dataset/myData/\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mmscaler = MinMaxScaler(feature_range=(-1, 1), copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 3 4 5 6 7] [8]\n"
     ]
    }
   ],
   "source": [
    "def random_idx_devide(all_num, test_ratio, subject_idx = 0):\n",
    "    test_num = int(all_num * test_ratio)\n",
    "    temp = np.arange(all_num)\n",
    "    temp = np.delete(temp, subject_idx)\n",
    "    np.random.shuffle(temp)\n",
    "    train_idx = temp[test_num:]\n",
    "    test_idx = temp[0:test_num]\n",
    "    train_idx.sort()\n",
    "    test_idx.sort()\n",
    "\n",
    "    return train_idx, test_idx\n",
    "\n",
    "train_idx, test_idx = random_idx_devide(subject_num, test_ratio, train_person)\n",
    "print(train_idx, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CsvFix.fix(path, subject_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data 0 (509, 128, 6)\n",
      "data 1 (458, 128, 6)\n",
      "data 2 (509, 128, 6)\n",
      "data 3 (94, 128, 6)\n",
      "data 4 (145, 128, 6)\n",
      "data 5 (147, 128, 6)\n",
      "data 6 (121, 128, 6)\n",
      "data 7 (148, 128, 6)\n",
      "data 8 (23, 128, 6)\n"
     ]
    }
   ],
   "source": [
    "#scale data set\n",
    "data = []\n",
    "for i in range(subject_num):\n",
    "    load = mmscaler.fit_transform(np.loadtxt(path + \"person_\" + str(i).zfill(3) + \"_out.csv\", delimiter=\",\", skiprows=100))\n",
    "    load = load[:,1:7]\n",
    "\n",
    "    preData = np.zeros((int(len(load) / seq_len), seq_len, input_size), float)\n",
    "    for j in range(int(len(load) / seq_len)):\n",
    "        preData[j,:,:] = load[j * seq_len : (j + 1) * seq_len, :]\n",
    "    \n",
    "    data.append(preData)\n",
    "    print(\"data\", i, preData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 128, 6)\n",
      "(40, 128, 6)\n",
      "(700,)\n",
      "(40,)\n"
     ]
    }
   ],
   "source": [
    "#trainnig person : other = 1 : 1\n",
    "trX = data[train_person][:train_size]\n",
    "for i in train_idx:\n",
    "    trX = np.vstack([trX, data[i][:train_size//len(train_idx)]])\n",
    "\n",
    "trY = np.hstack([np.zeros(train_size, int), np.ones(train_size, int)])\n",
    "\n",
    "teX = data[train_person][train_size:train_size + test_size]\n",
    "for i in test_idx:\n",
    "    teX = np.vstack([teX, data[i][:test_size // len(test_idx)]])\n",
    "\n",
    "teY = np.hstack([np.zeros(test_size, int), np.ones(test_size, int)])\n",
    "\n",
    "print(trX.shape)\n",
    "print(teX.shape)\n",
    "print(trY.shape)\n",
    "print(teY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX.shape:torch.Size([700, 128, 6])\n",
      "trainY.shape:torch.Size([700])\n",
      "testX.shape:torch.Size([40, 128, 6])\n",
      "testY.shape:torch.Size([40])\n",
      "trainY.shape:torch.Size([700, 2])\n"
     ]
    }
   ],
   "source": [
    "trainX = torch.Tensor(np.array(trX)).to(device)\n",
    "trainY = torch.Tensor(np.array(trY)).to(device)\n",
    "\n",
    "testX = torch.Tensor(np.array(teX)).to(device)\n",
    "testY = torch.Tensor(np.array(teY)).to(device)\n",
    "\n",
    "print('trainX.shape:{0}'.format(trainX.shape))\n",
    "print('trainY.shape:{0}'.format(trainY.shape))\n",
    "print('testX.shape:{0}'.format(testX.shape))\n",
    "print('testY.shape:{0}'.format(testY.shape))\n",
    "\n",
    "# trainYをone-hotにするためlongにsuru\n",
    "trainY = trainY.long()\n",
    "# one-hotにする \n",
    "trainY = F.one_hot(trainY, num_classes=output_size)\n",
    "# 誤差を計算できるようにfloatに直す\n",
    "trainY = trainY.float()\n",
    "# trY one-hotにする\n",
    "trY = trainY.cpu().data.numpy()\n",
    "\n",
    "#testY one-hot ni sinai!\n",
    "print('trainY.shape:{0}'.format(trainY.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.X = trX.astype(np.float32) # 入力\n",
    "        self.t = trY # 出力\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) # データ数(10)を返す\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # index番目の入出力ペアを返す\n",
    "        return self.X[index], self.t[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# さっき作ったDataSetクラスのインスタンスを作成\n",
    "dataset = DataSet()\n",
    "# datasetをDataLoaderの引数とすることでミニバッチを作成．\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch, \\\n",
    "                                         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size_1 = hidden_size_1\n",
    "        self.hidden_size_2 = hidden_size_2\n",
    "        self.lstm_1 = nn.LSTM(input_size=6, hidden_size=self.hidden_size_1, num_layers=1, batch_first=True) \n",
    "        self.lstm_2 = nn.LSTM(input_size=self.hidden_size_1, hidden_size=self.hidden_size_2, \\\n",
    "                              num_layers=1, batch_first=True) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(self.hidden_size_2, output_size)\n",
    "        #self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        c_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        h_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        c_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        out, (h_out, c_out) = self.lstm_1(x, (h_0, c_0))\n",
    "        _, (h_out, _) = self.lstm_2(out, (h_1, c_1))\n",
    "        h_out = h_out.view(-1, self.hidden_size_2)\n",
    "        h_out = self.relu(h_out)\n",
    "        y_hat = self.linear(h_out)\n",
    "        #y_hat = self.softmax(h_out)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, X, t):\n",
    "  model.train()\n",
    "  y_hat = model(X)\n",
    "  # print(y_hat.shape)\n",
    "  # loss = F.mse_loss(y_hat, trainY)\n",
    "  loss = nn.CrossEntropyLoss()\n",
    "  output = loss(y_hat, t)\n",
    "  optimizer.zero_grad()\n",
    "  output.backward()\n",
    "  optimizer.step()\n",
    "  return output.item()\n",
    "\n",
    "loss = []\n",
    "\n",
    "\n",
    "def main():\n",
    "  model = MyLSTM()\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "  model = model.to(device)\n",
    "  for epoch in range(epoch_num):\n",
    "    for X, t in dataloader:\n",
    "      _loss = train(model, optimizer, X.to(device), t.to(device))\n",
    "      loss.append(_loss)\n",
    "    if epoch % 20 == 0:\n",
    "      print(f\"Epoch = {epoch+1}, Loss = {_loss:.5f}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(engine, batch):\n",
    "    return batch\n",
    "\n",
    "default_evaluator = Engine(eval_step)\n",
    "\n",
    "# create default optimizer for doctests\n",
    "\n",
    "param_tensor = torch.zeros([1], requires_grad=True)\n",
    "default_optimizer = torch.optim.SGD([param_tensor], lr=learning_rate)\n",
    "\n",
    "# create default trainer for doctests\n",
    "# as handlers could be attached to the trainer,\n",
    "# each test must define his own trainer using `.. testsetup:`\n",
    "\n",
    "def get_default_trainer():\n",
    "\n",
    "    def train_step(engine, batch):\n",
    "        return batch\n",
    "\n",
    "    return Engine(train_step)\n",
    "\n",
    "# create default model for doctests\n",
    "\n",
    "# default_model = nn.Sequential(OrderedDict([\n",
    "#     ('base', nn.Linear(4, 2)),\n",
    "#     ('fc', nn.Linear(2, 1))\n",
    "# ]))\n",
    "\n",
    "# manual_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "  model.eval()\n",
    "  train_predict = model(testX)\n",
    "  print(train_predict.shape)\n",
    "\n",
    "  #data_predict = train_predict.cpu().data.numpy()\n",
    "  #testY_plot = testY.cpu().data.numpy()\n",
    "\n",
    "  \n",
    "  data_predict = torch.argmax(train_predict, dim=1)\n",
    "  data_predict = F.one_hot(data_predict, num_classes=output_size)\n",
    "  \n",
    "  metric = ConfusionMatrix(num_classes=output_size)\n",
    "  metric.attach(default_evaluator, 'cm')\n",
    "  y_true = testY.int()\n",
    "  y_pred = data_predict\n",
    "  print(y_true.shape)\n",
    "  print(y_pred.shape)\n",
    "\n",
    "  state = default_evaluator.run([[y_pred, y_true]])\n",
    "  print(state.metrics['cm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Loss = 0.69426\n",
      "Epoch = 21, Loss = 0.68749\n",
      "Epoch = 41, Loss = 0.66850\n",
      "Epoch = 61, Loss = 0.45312\n",
      "Epoch = 81, Loss = 0.02982\n",
      "Epoch = 101, Loss = 0.01098\n",
      "Epoch = 121, Loss = 0.00653\n",
      "Epoch = 141, Loss = 0.00450\n",
      "Epoch = 161, Loss = 0.00345\n",
      "Epoch = 181, Loss = 0.00283\n"
     ]
    }
   ],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 2])\n",
      "torch.Size([40])\n",
      "torch.Size([40, 2])\n",
      "tensor([[20,  0],\n",
      "        [ 0, 20]])\n"
     ]
    }
   ],
   "source": [
    "predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "slice step cannot be zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mセル19 を c:\\Users\\akota\\Desktop\\program\\MachineIntelligence\\myWalkDetect.ipynb\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/akota/Desktop/program/MachineIntelligence/myWalkDetect.ipynb#ch0000018?line=0'>1</a>\u001b[0m stop \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(loss)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/akota/Desktop/program/MachineIntelligence/myWalkDetect.ipynb#ch0000018?line=1'>2</a>\u001b[0m step \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(loss) \u001b[39m/\u001b[39m epoch_num)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/akota/Desktop/program/MachineIntelligence/myWalkDetect.ipynb#ch0000018?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(loss[\u001b[39m0\u001b[39;49m:stop:step], \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, label \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/akota/Desktop/program/MachineIntelligence/myWalkDetect.ipynb#ch0000018?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mValueError\u001b[0m: slice step cannot be zero"
     ]
    }
   ],
   "source": [
    "stop = len(loss)\n",
    "step = int(len(loss) / epoch_num)\n",
    "\n",
    "plt.plot(loss[0:stop:step], '.', label = \"test_error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = 'detect_person.pth'\n",
    "# torch.save(model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "be1730a4c75eedbbdd1e87842b276989c5900201d2db76eacd329e5d462cca92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
